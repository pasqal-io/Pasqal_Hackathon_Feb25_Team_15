{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"OKvXvthD9Krb","outputId":"64604652-295d-41fb-f844-a65355f34695","executionInfo":{"status":"ok","timestamp":1741548181152,"user_tz":-60,"elapsed":179102,"user":{"displayName":"Vincenzo Schiano","userId":"04691900049132186889"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Collecting qadence\n","  Downloading qadence-1.11.0-py3-none-any.whl.metadata (10 kB)\n","Collecting pulser\n","  Downloading pulser-1.3.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Collecting arpeggio==2.0.2 (from qadence)\n","  Downloading Arpeggio-2.0.2-py2.py3-none-any.whl.metadata (2.4 kB)\n","Collecting deepdiff (from qadence)\n","  Downloading deepdiff-8.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from qadence) (4.23.0)\n","Collecting nevergrad (from qadence)\n","  Downloading nevergrad-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Collecting openfermion (from qadence)\n","  Downloading openfermion-1.7.0-py3-none-any.whl.metadata (13 kB)\n","Collecting pasqal-cloud (from qadence)\n","  Downloading pasqal_cloud-0.20.2-py3-none-any.whl.metadata (13 kB)\n","Collecting pyqtorch==1.7.1 (from qadence)\n","  Downloading pyqtorch-1.7.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from qadence) (6.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from qadence) (13.9.4)\n","INFO: pip is looking at multiple versions of qadence to determine which version is compatible with other requirements. This could take a while.\n","Collecting qadence\n","  Downloading qadence-1.10.3-py3-none-any.whl.metadata (10 kB)\n","Collecting pyqtorch==1.7.0 (from qadence)\n","  Downloading pyqtorch-1.7.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.10.2-py3-none-any.whl.metadata (10 kB)\n","  Downloading qadence-1.10.1-py3-none-any.whl.metadata (10 kB)\n","  Downloading qadence-1.10.0-py3-none-any.whl.metadata (10.0 kB)\n","  Downloading qadence-1.9.2-py3-none-any.whl.metadata (10.0 kB)\n","  Downloading qadence-1.9.1-py3-none-any.whl.metadata (9.8 kB)\n","Collecting pyqtorch==1.6.0 (from qadence)\n","  Downloading pyqtorch-1.6.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.9.0-py3-none-any.whl.metadata (9.8 kB)\n","INFO: pip is still looking at multiple versions of qadence to determine which version is compatible with other requirements. This could take a while.\n","  Downloading qadence-1.8.0-py3-none-any.whl.metadata (9.9 kB)\n","Collecting pyqtorch==1.5.1 (from qadence)\n","  Downloading pyqtorch-1.5.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.8-py3-none-any.whl.metadata (10.0 kB)\n","Collecting pyqtorch==1.4.9 (from qadence)\n","  Downloading pyqtorch-1.4.9-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.7-py3-none-any.whl.metadata (10.0 kB)\n","Collecting pyqtorch==1.4.7 (from qadence)\n","  Downloading pyqtorch-1.4.7-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.6-py3-none-any.whl.metadata (9.9 kB)\n","Collecting pyqtorch==1.4.4 (from qadence)\n","  Downloading pyqtorch-1.4.4-py3-none-any.whl.metadata (3.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.5-py3-none-any.whl.metadata (9.9 kB)\n","Collecting pyqtorch==1.4.3 (from qadence)\n","  Downloading pyqtorch-1.4.3-py3-none-any.whl.metadata (3.9 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","Collecting qadence\n","  Downloading qadence-1.7.4-py3-none-any.whl.metadata (9.9 kB)\n","Collecting pyqtorch==1.3.2 (from qadence)\n","  Downloading pyqtorch-1.3.2-py3-none-any.whl.metadata (2.0 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.3-py3-none-any.whl.metadata (9.9 kB)\n","  Downloading qadence-1.7.2-py3-none-any.whl.metadata (9.8 kB)\n","Collecting pyqtorch==1.2.5 (from qadence)\n","  Downloading pyqtorch-1.2.5-py3-none-any.whl.metadata (1.9 kB)\n","Collecting qadence\n","  Downloading qadence-1.7.1-py3-none-any.whl.metadata (9.8 kB)\n","  Downloading qadence-1.7.0-py3-none-any.whl.metadata (9.6 kB)\n","Collecting pyqtorch==1.2.1 (from qadence)\n","  Downloading pyqtorch-1.2.1-py3-none-any.whl.metadata (1.7 kB)\n","Collecting sympytorch>=0.1.2 (from qadence)\n","  Downloading sympytorch-0.1.4-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: tensorboard>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from qadence) (2.18.0)\n","Collecting pulser-pasqal (from pulser)\n","  Downloading pulser_pasqal-0.20.2-py3-none-any.whl.metadata (1.5 kB)\n","Collecting pulser-core==1.3.0 (from pulser)\n","  Downloading pulser_core-1.3.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting pulser-simulation==1.3.0 (from pulser)\n","  Downloading pulser_simulation-1.3.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from pulser-core==1.3.0->pulser) (0.36.2)\n","Collecting qutip<6,>=5 (from pulser-simulation==1.3.0->pulser)\n","  Downloading qutip-5.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->qadence) (25.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->qadence) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->qadence) (0.23.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (1.70.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (75.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.0->qadence) (3.1.3)\n","Collecting orderly-set<6,>=5.3.0 (from deepdiff->qadence)\n","  Downloading orderly_set-5.3.0-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting cma>=2.6.0 (from nevergrad->qadence)\n","  Downloading cma-4.0.0-py3-none-any.whl.metadata (8.0 kB)\n","Collecting bayesian-optimization==1.4.0 (from nevergrad->qadence)\n","  Downloading bayesian_optimization-1.4.0-py3-none-any.whl.metadata (469 bytes)\n","Collecting colorama==0.4.0 (from nevergrad->qadence)\n","  Downloading colorama-0.4.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting directsearch (from nevergrad->qadence)\n","  Downloading directsearch-1.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting cirq-core (from openfermion->qadence)\n","  Downloading cirq_core-1.4.1-py3-none-any.whl.metadata (1.8 kB)\n","Collecting deprecation (from openfermion->qadence)\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from openfermion->qadence) (3.12.1)\n","Collecting pubchempy (from openfermion->qadence)\n","  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests~=2.32.2 in /usr/local/lib/python3.11/dist-packages (from openfermion->qadence) (2.32.3)\n","Collecting scipy>=1.6.0 (from scikit-learn)\n","  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting backoff~=2.2 (from pulser-pasqal->pulser)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Collecting auth0-python<4.0.0,>=3.23.1 (from pasqal-cloud->qadence)\n","  Downloading auth0_python-3.24.1-py2.py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: pyjwt<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->qadence) (2.10.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from pasqal-cloud->qadence) (2.10.6)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->qadence) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->qadence) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->qadence) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.2->openfermion->qadence) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.2->openfermion->qadence) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.2->openfermion->qadence) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.2->openfermion->qadence) (2025.1.31)\n","Collecting duet>=0.2.8 (from cirq-core->openfermion->qadence)\n","  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core->openfermion->qadence) (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cirq-core->openfermion->qadence) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->pasqal-cloud->qadence) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->pasqal-cloud->qadence) (2.27.2)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->qadence) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->qadence) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->qadence) (2.22)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading qadence-1.7.0-py3-none-any.whl (238 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Arpeggio-2.0.2-py2.py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyqtorch-1.2.1-py3-none-any.whl (27 kB)\n","Downloading pulser-1.3.0-py3-none-any.whl (6.8 kB)\n","Downloading pulser_core-1.3.0-py3-none-any.whl (220 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pulser_simulation-1.3.0-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympytorch-0.1.4-py3-none-any.whl (10 kB)\n","Downloading deepdiff-8.3.0-py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nevergrad-1.0.8-py3-none-any.whl (497 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bayesian_optimization-1.4.0-py3-none-any.whl (17 kB)\n","Downloading colorama-0.4.0-py2.py3-none-any.whl (21 kB)\n","Downloading openfermion-1.7.0-py3-none-any.whl (44.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pulser_pasqal-0.20.2-py3-none-any.whl (12 kB)\n","Downloading pasqal_cloud-0.20.2-py3-none-any.whl (38 kB)\n","Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading cma-4.0.0-py3-none-any.whl (283 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.5/283.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orderly_set-5.3.0-py3-none-any.whl (12 kB)\n","Downloading qutip-5.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cirq_core-1.4.1-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Downloading auth0_python-3.24.1-py2.py3-none-any.whl (122 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.6/122.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading duet-0.2.9-py3-none-any.whl (29 kB)\n","Building wheels for collected packages: directsearch, pubchempy\n","  Building wheel for directsearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for directsearch: filename=directsearch-1.0-py3-none-any.whl size=16297 sha256=1d40ecdfa6e0510d4b1dde4a2478a0aebae0d16ba039cc7664f8c856f80e32fa\n","  Stored in directory: /root/.cache/pip/wheels/02/a0/13/8e9d14b8e38244bf712bc5608c641b47c50d96f6e0f11a3280\n","  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pubchempy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13819 sha256=b77e7c4fc4945d1721b3d0fb7cd22c273415525eb7d6992f3f1dc8897f0eaac7\n","  Stored in directory: /root/.cache/pip/wheels/8b/e3/6c/3385b2db08b0985a87f5b117f98d0cb61a3ae3ca3bcbbd8307\n","Successfully built directsearch pubchempy\n","Installing collected packages: pubchempy, arpeggio, scipy, orderly-set, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, duet, deprecation, colorama, cma, backoff, qutip, nvidia-cusparse-cu12, nvidia-cudnn-cu12, directsearch, deepdiff, nvidia-cusolver-cu12, cirq-core, bayesian-optimization, pulser-core, openfermion, nevergrad, auth0-python, sympytorch, pyqtorch, pulser-simulation, pasqal-cloud, qadence, pulser-pasqal, pulser\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed arpeggio-2.0.2 auth0-python-3.24.1 backoff-2.2.1 bayesian-optimization-1.4.0 cirq-core-1.4.1 cma-4.0.0 colorama-0.4.0 deepdiff-8.3.0 deprecation-2.1.0 directsearch-1.0 duet-0.2.9 nevergrad-1.0.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openfermion-1.7.0 orderly-set-5.3.0 pasqal-cloud-0.20.2 pubchempy-1.0.4 pulser-1.3.0 pulser-core-1.3.0 pulser-pasqal-0.20.2 pulser-simulation-1.3.0 pyqtorch-1.2.1 qadence-1.7.0 qutip-5.1.1 scipy-1.15.2 sympytorch-0.1.4\n","Collecting quantum-evolution-kernel\n","  Downloading quantum_evolution_kernel-0.3.0-py3-none-any.whl.metadata (5.4 kB)\n","Collecting emu-mps~=1.2.0 (from quantum-evolution-kernel)\n","  Downloading emu_mps-1.2.6-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (3.10.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (3.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (1.26.4)\n","Requirement already satisfied: pasqal-cloud in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (0.20.2)\n","Collecting pulser==1.1.1 (from quantum-evolution-kernel)\n","  Downloading pulser-1.1.1-py3-none-any.whl.metadata (4.0 kB)\n","Collecting rdkit (from quantum-evolution-kernel)\n","  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (1.6.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from quantum-evolution-kernel) (2.5.1+cu124)\n","Collecting torch-geometric (from quantum-evolution-kernel)\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pulser-pasqal in /usr/local/lib/python3.11/dist-packages (from pulser==1.1.1->quantum-evolution-kernel) (0.20.2)\n","Collecting pulser-core==1.1.1 (from pulser==1.1.1->quantum-evolution-kernel)\n","  Downloading pulser_core-1.1.1-py3-none-any.whl.metadata (1.2 kB)\n","Collecting pulser-simulation==1.1.1 (from pulser==1.1.1->quantum-evolution-kernel)\n","  Downloading pulser_simulation-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: jsonschema<5,>=4.17.3 in /usr/local/lib/python3.11/dist-packages (from pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (4.23.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (0.36.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (24.2)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (1.15.2)\n","Collecting qutip~=4.7.5 (from pulser-simulation==1.1.1->pulser==1.1.1->quantum-evolution-kernel)\n","  Downloading qutip-4.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting scipy<2 (from pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel)\n","  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emu-base==1.2.6 (from emu-mps~=1.2.0->quantum-evolution-kernel)\n","  Downloading emu_base-1.2.6-py3-none-any.whl.metadata (3.5 kB)\n","INFO: pip is looking at multiple versions of emu-base to determine which version is compatible with other requirements. This could take a while.\n","Collecting emu-mps~=1.2.0 (from quantum-evolution-kernel)\n","  Downloading emu_mps-1.2.5-py3-none-any.whl.metadata (5.6 kB)\n","Collecting emu-base==1.2.5 (from emu-mps~=1.2.0->quantum-evolution-kernel)\n","  Downloading emu_base-1.2.5-py3-none-any.whl.metadata (5.6 kB)\n","Collecting emu-mps~=1.2.0 (from quantum-evolution-kernel)\n","  Downloading emu_mps-1.2.4-py3-none-any.whl.metadata (5.5 kB)\n","Collecting emu-base==1.2.4 (from emu-mps~=1.2.0->quantum-evolution-kernel)\n","  Downloading emu_base-1.2.4-py3-none-any.whl.metadata (5.5 kB)\n","Collecting torch (from quantum-evolution-kernel)\n","  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (4.12.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->quantum-evolution-kernel) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->quantum-evolution-kernel) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->quantum-evolution-kernel) (2.8.2)\n","Requirement already satisfied: auth0-python<4.0.0,>=3.23.1 in /usr/local/lib/python3.11/dist-packages (from pasqal-cloud->quantum-evolution-kernel) (3.24.1)\n","Requirement already satisfied: requests<3.0.0,>=2.25.1 in /usr/local/lib/python3.11/dist-packages (from pasqal-cloud->quantum-evolution-kernel) (2.32.3)\n","Requirement already satisfied: pyjwt<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->quantum-evolution-kernel) (2.10.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from pasqal-cloud->quantum-evolution-kernel) (2.10.6)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->quantum-evolution-kernel) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->quantum-evolution-kernel) (3.5.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->quantum-evolution-kernel) (3.11.13)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->quantum-evolution-kernel) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->quantum-evolution-kernel) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->pasqal-cloud->quantum-evolution-kernel) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.0->pasqal-cloud->quantum-evolution-kernel) (2.27.2)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->quantum-evolution-kernel) (43.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->quantum-evolution-kernel) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.25.1->pasqal-cloud->quantum-evolution-kernel) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.25.1->pasqal-cloud->quantum-evolution-kernel) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.25.1->pasqal-cloud->quantum-evolution-kernel) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.25.1->pasqal-cloud->quantum-evolution-kernel) (2025.1.31)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->quantum-evolution-kernel) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->quantum-evolution-kernel) (3.0.2)\n","INFO: pip is looking at multiple versions of pulser-pasqal to determine which version is compatible with other requirements. This could take a while.\n","Collecting pulser-pasqal (from pulser==1.1.1->quantum-evolution-kernel)\n","  Downloading pulser_pasqal-0.20.1-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: backoff~=2.2 in /usr/local/lib/python3.11/dist-packages (from pulser-pasqal->pulser==1.1.1->quantum-evolution-kernel) (2.2.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->quantum-evolution-kernel) (1.17.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4.17.3->pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4.17.3->pulser-core==1.1.1->pulser==1.1.1->quantum-evolution-kernel) (0.23.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]<3.0.0,>=2.5.0->pasqal-cloud->quantum-evolution-kernel) (2.22)\n","Downloading quantum_evolution_kernel-0.3.0-py3-none-any.whl (35 kB)\n","Downloading pulser-1.1.1-py3-none-any.whl (6.8 kB)\n","Downloading pulser_core-1.1.1-py3-none-any.whl (201 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pulser_simulation-1.1.1-py3-none-any.whl (35 kB)\n","Downloading emu_mps-1.2.4-py3-none-any.whl (29 kB)\n","Downloading emu_base-1.2.4-py3-none-any.whl (21 kB)\n","Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pulser_pasqal-0.20.1-py3-none-any.whl (13 kB)\n","Downloading qutip-4.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scipy, rdkit, qutip, torch-geometric, torch, pulser-core, pulser-simulation, emu-base, pulser-pasqal, emu-mps, pulser, quantum-evolution-kernel\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.15.2\n","    Uninstalling scipy-1.15.2:\n","      Successfully uninstalled scipy-1.15.2\n","  Attempting uninstall: qutip\n","    Found existing installation: qutip 5.1.1\n","    Uninstalling qutip-5.1.1:\n","      Successfully uninstalled qutip-5.1.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","  Attempting uninstall: pulser-core\n","    Found existing installation: pulser-core 1.3.0\n","    Uninstalling pulser-core-1.3.0:\n","      Successfully uninstalled pulser-core-1.3.0\n","  Attempting uninstall: pulser-simulation\n","    Found existing installation: pulser-simulation 1.3.0\n","    Uninstalling pulser-simulation-1.3.0:\n","      Successfully uninstalled pulser-simulation-1.3.0\n","  Attempting uninstall: pulser-pasqal\n","    Found existing installation: pulser-pasqal 0.20.2\n","    Uninstalling pulser-pasqal-0.20.2:\n","      Successfully uninstalled pulser-pasqal-0.20.2\n","  Attempting uninstall: pulser\n","    Found existing installation: pulser 1.3.0\n","    Uninstalling pulser-1.3.0:\n","      Successfully uninstalled pulser-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","openfermion 1.7.0 requires scipy~=1.15, but you have scipy 1.12.0 which is incompatible.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed emu-base-1.2.4 emu-mps-1.2.4 pulser-1.1.1 pulser-core-1.1.1 pulser-pasqal-0.20.1 pulser-simulation-1.1.1 quantum-evolution-kernel-0.3.0 qutip-4.7.6 rdkit-2024.9.5 scipy-1.12.0 torch-2.5.0 torch-geometric-2.6.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen"]},"id":"29799cf851024959a7c8cdffb505f986"}},"metadata":{}}],"source":["!pip install numpy pandas scikit-learn matplotlib seaborn torch qadence pulser\n","!pip install quantum-evolution-kernel"]},{"cell_type":"code","source":[],"metadata":{"id":"ZFQPP86QyB_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Google Colab version with online data access.\n","\n","This notebook demonstrates a comprehensive hybrid approach for predicting coral reef bleaching using a NOAA dataset.\n","Instead of reading a local CSV, the dataset is loaded from an online source (GitHub).\n","\"\"\"\n","\n","# =============================================================================\n","# Section 1: Introduction & Setup\n","# =============================================================================\n","import os\n","import sys\n","import time\n","import warnings\n","from math import pi as PI_value\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score, confusion_matrix, classification_report,\n","    precision_score, recall_score, f1_score, balanced_accuracy_score\n",")\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.preprocessing import StandardScaler\n","\n","warnings.filterwarnings(\"ignore\")\n","print(\"Coral Reef Bleaching Prediction using Classical and Quantum ML Approaches\")\n","\n","# =============================================================================\n","# Section 2: Data Loading and Preprocessing (Online Access)\n","# =============================================================================\n","def load_and_preprocess_data():\n","    \"\"\"\n","    Load and preprocess the NOAA coral reef bleaching dataset from an online source.\n","\n","    Returns:\n","        tuple: X_train_scaled, X_test_scaled, y_train, y_test, feature_names, df\n","    \"\"\"\n","    # Use the online CSV from GitHub (as used in other notebooks)\n","    data_url = \"https://raw.githubusercontent.com/alyshapm/coral-reef-bleaching/main/dataset/NOAA_Reef_Check__Bleaching_Data.csv\"\n","    print(\"Loading data from online URL:\", data_url)\n","    df = pd.read_csv(data_url)\n","    print(\"Original dataset shape:\", df.shape)\n","    print(df.head())\n","\n","    # Clean the dataset: remove duplicates\n","    df.drop_duplicates(inplace=True)\n","\n","    # Display class distribution before cleaning\n","    if 'Bleaching' in df.columns:\n","        bleaching_counts = df['Bleaching'].value_counts()\n","        print(\"\\nClass distribution before cleaning:\")\n","        print(bleaching_counts)\n","        print(f\"Positive rate: {bleaching_counts.get('Yes', 0) / len(df):.2%}\")\n","\n","    # Standardize column names - replace spaces with underscores\n","    df.columns = [col.replace(' ', '') for col in df.columns]\n","\n","    # Check for columns with all missing values\n","    all_na_columns = [col for col in df.columns if df[col].isna().all()]\n","    if all_na_columns:\n","        print(f\"Dropping columns with all missing values: {all_na_columns}\")\n","        df.drop(columns=all_na_columns, inplace=True)\n","\n","    # Handle missing values first: replace with mode for categorical, mean for numerical\n","    for col in df.columns:\n","        if df[col].isna().any():\n","            print(f\"Handling missing values in {col} column: {df[col].isna().sum()} NaNs\")\n","            if df[col].dtype == 'object':\n","                # For categorical columns, fill with mode\n","                if not df[col].dropna().empty:  # Only if there are non-NaN values\n","                    mode_value = df[col].mode()[0]\n","                    df[col].fillna(mode_value, inplace=True)\n","                else:\n","                    # If all values are NaN, fill with a default value\n","                    print(f\"Column {col} has all NaN values, filling with 'none'\")\n","                    df[col].fillna('none', inplace=True)\n","            else:\n","                # For numerical columns, fill with mean or 0 if all NaN\n","                if not df[col].dropna().empty:  # Only if there are non-NaN values\n","                    mean_value = df[col].mean()\n","                    df[col].fillna(mean_value, inplace=True)\n","                else:\n","                    print(f\"Column {col} has all NaN values, filling with 0\")\n","                    df[col].fillna(0, inplace=True)\n","\n","    print(f\"Shape after handling missing values: {df.shape}\")\n","\n","    # Display data types\n","    print(\"\\nColumn data types:\")\n","    print(df.dtypes)\n","\n","    print(\"\\nEncoding categorical columns...\")\n","    # Encode all categorical columns\n","\n","    # Binary categorical columns - map Yes/No, yes/no to 1/0\n","    binary_columns = [\"Bleaching\", \"Storms\"]\n","    for col in binary_columns:\n","        if col in df.columns:\n","            # Handle case insensitivity\n","            df[col] = df[col].astype(str).str.lower()\n","            df[col] = df[col].map({\"yes\": 1, \"no\": 0})\n","            print(f\"Encoded {col} to 1/0\")\n","\n","    # Ocean categorical column\n","    if 'Ocean' in df.columns:\n","        ocean_mapping = {\"Arabian Gulf\": 0, \"Atlantic\": 1, \"Indian\": 2, \"Pacific\": 3, \"Red Sea\": 4}\n","        df['Ocean'] = df['Ocean'].map(ocean_mapping)\n","        print(\"Encoded Ocean column\")\n","\n","    # Impact categorical columns with consistent naming\n","    impact_columns = ['Commercial', 'HumanImpact', 'Siltation', 'Dynamite', 'Poison', 'Sewage', 'Industrial']\n","    for col in impact_columns:\n","        if col in df.columns:\n","            # First, standardize values to lowercase and strip whitespace\n","            df[col] = df[col].astype(str).str.lower().str.strip()\n","\n","            # Display unique values before mapping\n","            unique_values = df[col].unique()\n","            print(f\"Unique values in {col} before mapping: {unique_values}\")\n","\n","            # Map values\n","            mapping = {'none': 0, 'low': 1, 'moderate': 2, 'high': 3, 'nan': 0}\n","            df[col] = df[col].map(mapping)\n","\n","            # Check if mapping was successful\n","            if df[col].isna().any():\n","                print(f\"Warning: Column {col} has {df[col].isna().sum()} NaN values after mapping\")\n","                print(f\"Unique values in {col} after mapping: {df[col].unique()}\")\n","\n","                # Fill NaN with 0 (representing 'none')\n","                df[col].fillna(0, inplace=True)\n","                print(f\"Filled NaN values in {col} with 0\")\n","\n","            print(f\"Encoded {col} column\")\n","\n","    # Check for any remaining object columns\n","    object_columns = df.select_dtypes(include=['object']).columns.tolist()\n","    if object_columns:\n","        print(f\"Warning: The following columns still have non-numeric types: {object_columns}\")\n","        print(\"Converting remaining object columns to numeric if possible...\")\n","\n","        for col in object_columns:\n","            try:\n","                # Display unique values to help with debugging\n","                print(f\"Unique values in {col}: {df[col].unique()}\")\n","                df[col] = pd.to_numeric(df[col], errors='coerce')\n","                # Fill NaN with mean or mode\n","                if df[col].isna().any():\n","                    if df[col].nunique() > 10:  # If many unique values, use mean\n","                        if not df[col].dropna().empty:\n","                            df[col].fillna(df[col].mean(), inplace=True)\n","                        else:\n","                            df[col].fillna(0, inplace=True)\n","                    else:  # If few unique values, use mode\n","                        if not df[col].dropna().empty:\n","                            df[col].fillna(df[col].mode()[0], inplace=True)\n","                        else:\n","                            df[col].fillna(0, inplace=True)\n","                print(f\"Converted {col} to numeric\")\n","            except Exception as e:\n","                print(f\"Could not convert {col} to numeric: {e}, dropping column\")\n","                df.drop(columns=[col], inplace=True)\n","\n","    # Final check for NaN values\n","    nan_check = df.isna().sum()\n","    if nan_check.sum() > 0:\n","        print(\"\\nWarning: Dataset still contains NaN values:\")\n","        print(nan_check[nan_check > 0])\n","        print(\"Filling remaining NaN values...\")\n","        # Fill remaining NaN values with column means or 0\n","        for col in df.columns:\n","            if df[col].isna().any():\n","                if df[col].dtype.kind in 'ifc':  # integer, float, complex\n","                    if not df[col].dropna().empty:\n","                        df[col].fillna(df[col].mean(), inplace=True)\n","                    else:\n","                        df[col].fillna(0, inplace=True)\n","                else:\n","                    df[col].fillna(0, inplace=True)  # Default to 0 for any type\n","\n","    # Compute correlation matrix and drop features with very low correlation with 'Bleaching'\n","    try:\n","        corr_matrix = df.corr()\n","        low_corr_features = []\n","        threshold = 0.1\n","\n","        # Print all correlations with Bleaching\n","        print(\"\\nCorrelations with Bleaching:\")\n","        for col in df.columns:\n","            if col != 'Bleaching' and col in corr_matrix.index:\n","                corr_value = abs(corr_matrix.loc[col, 'Bleaching'])\n","                print(f\"Correlation of {col} with Bleaching: {corr_value:.4f}\")\n","                if corr_value < threshold:\n","                    low_corr_features.append(col)\n","\n","        if low_corr_features:\n","            print(f\"Dropping low correlation features: {low_corr_features}\")\n","            df.drop(columns=low_corr_features, inplace=True)\n","    except Exception as e:\n","        print(f\"Error computing correlations: {e}\")\n","        print(\"Skipping correlation-based feature selection\")\n","\n","    # Define features and target\n","    X = df.drop(columns=['Bleaching'])\n","    y = df['Bleaching']\n","    feature_names = X.columns.tolist()\n","\n","    # Check for class imbalance\n","    print(\"\\nClass distribution after preprocessing:\")\n","    print(y.value_counts())\n","    print(f\"Positive rate: {y.mean():.2%}\")\n","\n","    # If the dataset is imbalanced, use stratified sampling\n","    if y.mean() < 0.2:  # If positive class is less than 20%\n","        print(\"Dataset is imbalanced. Using stratified sampling...\")\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y, test_size=0.25, random_state=42, stratify=y\n","        )\n","    else:\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y, test_size=0.25, random_state=42\n","        )\n","\n","    # Apply feature scaling\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    # Verify no NaNs in the scaled data\n","    if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n","        print(\"Warning: NaN values detected after scaling. Replacing with zeros...\")\n","        X_train_scaled = np.nan_to_num(X_train_scaled)\n","        X_test_scaled = np.nan_to_num(X_test_scaled)\n","\n","    print(f\"Training data shape: {X_train_scaled.shape}\")\n","    print(f\"Test data shape: {X_test_scaled.shape}\")\n","    print(f\"Training set positive rate: {y_train.mean():.2%}\")\n","    print(f\"Test set positive rate: {y_test.mean():.2%}\")\n","\n","    return X_train_scaled, X_test_scaled, y_train, y_test, feature_names, df\n","\n","# =============================================================================\n","# Section 3: Classical Machine Learning Models\n","# =============================================================================\n","def train_and_evaluate_classical_models(X_train_scaled, X_test_scaled, y_train, y_test):\n","    \"\"\"\n","    Train and evaluate classical machine learning models.\n","\n","    Args:\n","        X_train_scaled: Scaled training features\n","        X_test_scaled: Scaled test features\n","        y_train: Training target\n","        y_test: Test target\n","\n","    Returns:\n","        dict: Results of classical models\n","    \"\"\"\n","    # Check for class imbalance and prepare model parameters accordingly\n","    class_counts = np.bincount(y_train)\n","    total_samples = len(y_train)\n","    if len(class_counts) > 1:\n","        minority_class_ratio = min(class_counts) / total_samples\n","        print(f\"Minority class ratio: {minority_class_ratio:.2%}\")\n","\n","        # Adjust model parameters for imbalanced data if needed\n","        imbalanced = minority_class_ratio < 0.2\n","    else:\n","        imbalanced = False\n","        print(\"Warning: Only one class found in training data\")\n","\n","    # Define models with parameters adjusted for potential class imbalance\n","    if imbalanced:\n","        print(\"Using class weight 'balanced' for models due to imbalanced data\")\n","        models = {\n","            \"Logistic Regression\": LogisticRegression(\n","                max_iter=1000,\n","                random_state=42,\n","                class_weight='balanced',\n","                solver='liblinear'  # More stable with imbalanced data\n","            ),\n","            \"Decision Tree\": DecisionTreeClassifier(\n","                random_state=42,\n","                class_weight='balanced',\n","                min_samples_leaf=5  # Prevent overfitting to minority class\n","            ),\n","            \"SVM\": SVC(\n","                kernel='rbf',\n","                probability=True,\n","                random_state=42,\n","                class_weight='balanced'\n","            ),\n","            \"Naive Bayes\": GaussianNB()  # No class_weight parameter for GaussianNB\n","        }\n","    else:\n","        models = {\n","            \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n","            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n","            \"SVM\": SVC(kernel='rbf', probability=True, random_state=42),\n","            \"Naive Bayes\": GaussianNB()\n","        }\n","\n","    classical_results = {}\n","\n","    print(\"\\n----- Classical Model Results -----\")\n","    for name, model in models.items():\n","        try:\n","            # Verify no NaN values\n","            if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n","                print(f\"Warning: NaN values detected before training {name}. Replacing with zeros...\")\n","                X_train_clean = np.nan_to_num(X_train_scaled)\n","                X_test_clean = np.nan_to_num(X_test_scaled)\n","            else:\n","                X_train_clean = X_train_scaled\n","                X_test_clean = X_test_scaled\n","\n","            start_time = time.time()\n","            model.fit(X_train_clean, y_train)\n","            training_time = time.time() - start_time\n","\n","            y_pred = model.predict(X_test_clean)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            cm = confusion_matrix(y_test, y_pred)\n","\n","            # Calculate additional metrics for imbalanced data\n","            precision = precision_score(y_test, y_pred, zero_division=0)\n","            recall = recall_score(y_test, y_pred, zero_division=0)\n","            f1 = f1_score(y_test, y_pred, zero_division=0)\n","            balanced_acc = balanced_accuracy_score(y_test, y_pred)\n","\n","            classical_results[name] = {\n","                \"accuracy\": accuracy,\n","                \"balanced_accuracy\": balanced_acc,\n","                \"precision\": precision,\n","                \"recall\": recall,\n","                \"f1_score\": f1,\n","                \"confusion_matrix\": cm,\n","                \"training_time\": training_time\n","            }\n","\n","            print(f\"{name} Results:\")\n","            print(f\"  Accuracy: {accuracy:.4f}\")\n","            print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n","            print(f\"  Precision: {precision:.4f}\")\n","            print(f\"  Recall: {recall:.4f}\")\n","            print(f\"  F1 Score: {f1:.4f}\")\n","            print(f\"  Training Time: {training_time:.4f} seconds\")\n","            print(f\"  Confusion Matrix:\\n{cm}\")\n","            print(f\"  Classification Report:\\n{classification_report(y_test, y_pred, zero_division=0)}\")\n","            print(\"-----\")\n","        except Exception as e:\n","            print(f\"Error training {name}: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","\n","    return classical_results\n","\n","# =============================================================================\n","# Section 4: Quantum Machine Learning Model using Qadence (QNN)\n","# =============================================================================\n","def train_and_evaluate_quantum_model(X_train_scaled, X_test_scaled, y_train, y_test):\n","    \"\"\"\n","    Train and evaluate a quantum machine learning model using Qadence.\n","\n","    Args:\n","        X_train_scaled: Scaled training features\n","        X_test_scaled: Scaled test features\n","        y_train: Training target\n","        y_test: Test target\n","\n","    Returns:\n","        tuple: Quantum model accuracy and training time\n","    \"\"\"\n","    print(\"\\n----- Quantum Model (QNN) -----\")\n","    try:\n","        # Import Qadence for constructing the quantum circuit\n","        from qadence import QNN, QuantumCircuit, RX, RY, CNOT, Z, chain, FeatureParameter\n","\n","        # Check for NaN values and replace them\n","        if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n","            print(\"Warning: NaN values detected. Replacing with zeros for quantum model.\")\n","            X_train_scaled_clean = np.nan_to_num(X_train_scaled)\n","            X_test_scaled_clean = np.nan_to_num(X_test_scaled)\n","        else:\n","            X_train_scaled_clean = X_train_scaled\n","            X_test_scaled_clean = X_test_scaled\n","\n","        # For the quantum model, select features with highest correlation to target\n","        if X_train_scaled_clean.shape[1] >= 2:\n","            # Select the two features with highest correlation to target\n","            if X_train_scaled_clean.shape[1] > 2:\n","                # Calculate correlation with target for each feature\n","                correlations = []\n","                for i in range(X_train_scaled_clean.shape[1]):\n","                    corr = np.corrcoef(X_train_scaled_clean[:, i], y_train)[0, 1]\n","                    correlations.append((i, abs(corr)))\n","\n","                # Sort by absolute correlation and get top 2 feature indices\n","                top_features = sorted(correlations, key=lambda x: x[1], reverse=True)[:2]\n","                feature_indices = [idx for idx, _ in top_features]\n","                print(f\"Using features with indices {feature_indices} for quantum model (highest correlations)\")\n","            else:\n","                feature_indices = [0, 1]\n","                print(f\"Using the two available features for quantum model\")\n","\n","            X_train_q = X_train_scaled_clean[:, feature_indices]\n","            X_test_q = X_test_scaled_clean[:, feature_indices]\n","        else:\n","            # If only one feature is available, duplicate it\n","            X_train_q = np.hstack([X_train_scaled_clean, X_train_scaled_clean])\n","            X_test_q = np.hstack([X_test_scaled_clean, X_test_scaled_clean])\n","            print(f\"Using duplicated features for quantum model (only {X_train_scaled_clean.shape[1]} feature available)\")\n","\n","        # Normalize to [0, PI] for encoding as rotation angles\n","        min_vals = X_train_q.min(axis=0)\n","        max_vals = X_train_q.max(axis=0)\n","        # Prevent division by zero\n","        ranges = max_vals - min_vals\n","        ranges[ranges == 0] = 1.0  # Replace zero ranges with 1.0\n","\n","        X_train_q_norm = (X_train_q - min_vals) / ranges * PI_value\n","        X_test_q_norm = (X_test_q - min_vals) / ranges * PI_value\n","\n","        # Check for NaN or inf values after normalization\n","        if np.isnan(X_train_q_norm).any() or np.isnan(X_test_q_norm).any() or \\\n","           np.isinf(X_train_q_norm).any() or np.isinf(X_test_q_norm).any():\n","            print(\"Warning: NaN or inf values detected after normalization. Replacing with PI/2.\")\n","            X_train_q_norm = np.nan_to_num(X_train_q_norm, nan=PI_value/2, posinf=PI_value, neginf=0)\n","            X_test_q_norm = np.nan_to_num(X_test_q_norm, nan=PI_value/2, posinf=PI_value, neginf=0)\n","\n","        # Convert target to numpy array if it's a pandas Series\n","        if hasattr(y_train, 'values'):\n","            y_train_np = y_train.values\n","            y_test_np = y_test.values\n","        else:\n","            y_train_np = y_train\n","            y_test_np = y_test\n","\n","        # Convert to PyTorch tensors\n","        X_train_q_tensor = torch.tensor(X_train_q_norm, dtype=torch.float64)\n","        y_train_tensor = torch.tensor(y_train_np, dtype=torch.float64).view(-1, 1)\n","        X_test_q_tensor = torch.tensor(X_test_q_norm, dtype=torch.float64)\n","        y_test_tensor = torch.tensor(y_test_np, dtype=torch.float64).view(-1, 1)\n","\n","        print(f\"Training tensor shape: {X_train_q_tensor.shape}\")\n","        print(f\"Target tensor shape: {y_train_tensor.shape}\")\n","\n","        # Handle class imbalance by creating weighted sampling\n","        # Calculate class weights\n","        class_counts = np.bincount(y_train_np.astype(int))\n","        weights = 1.0 / class_counts\n","        sample_weights = torch.tensor([weights[t] for t in y_train_np.astype(int)], dtype=torch.float64)\n","        sampler = torch.utils.data.WeightedRandomSampler(\n","            weights=sample_weights,\n","            num_samples=len(sample_weights),\n","            replacement=True\n","        )\n","\n","        # Create DataLoader with weighted sampling\n","        batch_size = 128  # Using batches to improve training\n","        dataset = torch.utils.data.TensorDataset(X_train_q_tensor, y_train_tensor)\n","        train_loader = torch.utils.data.DataLoader(\n","            dataset=dataset,\n","            batch_size=batch_size,\n","            sampler=sampler\n","        )\n","\n","        # Build a 3-qubit quantum circuit with trainable parameters for better expressivity\n","        from qadence import Parameter\n","\n","        # Create trainable parameters\n","        theta1 = Parameter(\"theta1\")\n","        theta2 = Parameter(\"theta2\")\n","        theta3 = Parameter(\"theta3\")\n","        theta4 = Parameter(\"theta4\")\n","\n","        # Build an enhanced quantum circuit with both feature encoding and trainable parameters\n","        qnn_block = chain(\n","            # Initial feature encoding layer\n","            RX(0, FeatureParameter(\"phi\")),       # Encode first feature\n","            RX(1, FeatureParameter(\"theta\")),     # Encode second feature\n","            CNOT(0, 1),                           # Entangling gate\n","\n","            # First trainable layer\n","            RY(0, theta1),                        # Trainable rotation\n","            RY(1, theta2),                        # Trainable rotation\n","            CNOT(1, 0),                           # Entangling gate\n","\n","            # Second trainable layer\n","            RY(0, theta3),                        # Trainable rotation\n","            RY(1, theta4),                        # Trainable rotation\n","            CNOT(0, 1),                           # Entangling gate\n","\n","            # Feature re-encoding for better feature interaction\n","            RY(0, FeatureParameter(\"phi\")),       # Encode first feature again\n","            RY(1, FeatureParameter(\"theta\")),     # Encode second feature again\n","            CNOT(0, 1)                            # Final entangling gate\n","        )\n","\n","        qc = QuantumCircuit(2, qnn_block)\n","        observable = Z(0)  # Measure qubit 0\n","\n","        # Create QNN with trainable parameters\n","        qnn_model = QNN(\n","            qc,\n","            observable,\n","            inputs=[\"phi\", \"theta\"]\n","        )\n","\n","        # Print parameter names to verify\n","        print(f\"QNN parameters: {qnn_model.parameters()}\")\n","\n","        if len(list(qnn_model.parameters())) == 0:\n","            print(\"Warning: QNN has no trainable parameters. Using a different approach.\")\n","\n","            # Create a simpler fixed circuit for demonstration\n","            qnn_model = None\n","            quantum_accuracy = None\n","            quantum_training_time = None\n","        else:\n","            # Wrap the QNN in a PyTorch Module for classification\n","            class QuantumClassifier(nn.Module):\n","                def __init__(self, qnn):\n","                    super(QuantumClassifier, self).__init__()\n","                    self.qnn = qnn\n","                    # Add a classical layer to help with classification decision boundary\n","                    self.post_process = nn.Sequential(\n","                        nn.Linear(1, 4),\n","                        nn.ReLU(),\n","                        nn.Linear(4, 1),\n","                        nn.Sigmoid()\n","                    )\n","\n","                def forward(self, x):\n","                    out = self.qnn(x).view(-1, 1)  # Expectation value in [-1, 1]\n","                    # Process through classical layer for better classification\n","                    return self.post_process(out)\n","\n","            quantum_classifier = QuantumClassifier(qnn_model)\n","\n","            # Loss and optimizer\n","            # Use weighted binary cross-entropy loss to handle class imbalance\n","            pos_weight = torch.tensor([class_counts[0] / class_counts[1]], dtype=torch.float64)\n","            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","\n","            # Use a learning rate scheduler for better convergence\n","            optimizer = optim.Adam(quantum_classifier.parameters(), lr=0.01)\n","            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","                optimizer, mode='min', factor=0.5, patience=10, verbose=True\n","            )\n","\n","            # Training loop for the QNN model\n","            num_epochs = 200  # Increased number of epochs\n","            quantum_training_start = time.time()\n","\n","            # Keep track of best model\n","            best_f1 = 0\n","            best_model_state = None\n","\n","            try:\n","                for epoch in range(num_epochs):\n","                    epoch_loss = 0\n","                    # Train with batches\n","                    for batch_x, batch_y in train_loader:\n","                        optimizer.zero_grad()\n","                        outputs = quantum_classifier(batch_x)\n","                        loss = criterion(outputs, batch_y)\n","                        loss.backward()\n","                        optimizer.step()\n","                        epoch_loss += loss.item()\n","\n","                    avg_loss = epoch_loss / len(train_loader)\n","                    scheduler.step(avg_loss)\n","\n","                    # Evaluate every 20 epochs\n","                    if (epoch+1) % 20 == 0:\n","                        with torch.no_grad():\n","                            q_outputs = quantum_classifier(X_test_q_tensor)\n","                            q_preds = (q_outputs >= 0.5).float()\n","                            # Make sure we're importing the correct f1_score from sklearn.metrics\n","                            from sklearn.metrics import f1_score as sklearn_f1_score\n","                            current_f1 = sklearn_f1_score(y_test_tensor.cpu().numpy().flatten(), q_preds.cpu().numpy().flatten(), average='binary')\n","\n","                            if current_f1 > best_f1:\n","                                best_f1 = current_f1\n","                                best_model_state = {k: v.clone() for k, v in quantum_classifier.state_dict().items()}\n","\n","                        print(f\"Quantum Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Current F1: {current_f1:.4f}\")\n","            except Exception as e:\n","                print(f\"Error during quantum model training: {e}\")\n","                print(\"Skipping further quantum model evaluation\")\n","                return None, None\n","\n","            quantum_training_time = time.time() - quantum_training_start\n","\n","            # Load the best model state\n","            if best_model_state:\n","                quantum_classifier.load_state_dict(best_model_state)\n","\n","            # Evaluate QNN on test set\n","            with torch.no_grad():\n","                q_outputs = quantum_classifier(X_test_q_tensor)\n","                q_preds = (q_outputs >= 0.5).float()\n","                quantum_accuracy = (q_preds.eq(y_test_tensor).sum().item()) / y_test_tensor.size(0)\n","\n","            # Calculate additional metrics for imbalanced data\n","            from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n","\n","            q_preds_np = q_preds.cpu().numpy().flatten()\n","            y_test_np = y_test_tensor.cpu().numpy().flatten()\n","\n","            try:\n","                precision = precision_score(y_test_np, q_preds_np, zero_division=0)\n","                recall = recall_score(y_test_np, q_preds_np, zero_division=0)\n","                f1 = f1_score(y_test_np, q_preds_np, zero_division=0)\n","                balanced_acc = balanced_accuracy_score(y_test_np, q_preds_np)\n","\n","                print(f\"Quantum QNN Model Results:\")\n","                print(f\"  Accuracy: {quantum_accuracy:.4f}\")\n","                print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n","                print(f\"  Precision: {precision:.4f}\")\n","                print(f\"  Recall: {recall:.4f}\")\n","                print(f\"  F1 Score: {f1:.4f}\")\n","                print(f\"  Training Time: {quantum_training_time:.4f} seconds\")\n","                print(f\"  Confusion Matrix:\\n{confusion_matrix(y_test_np, q_preds_np)}\")\n","                print(f\"  Classification Report:\\n{classification_report(y_test_np, q_preds_np, zero_division=0)}\")\n","            except Exception as e:\n","                print(f\"Error calculating quantum model metrics: {e}\")\n","\n","            # Create a results dictionary similar to classical models\n","            quantum_results = None\n","            if quantum_accuracy is not None:\n","                quantum_results = {\n","                    \"accuracy\": quantum_accuracy,\n","                    \"balanced_accuracy\": balanced_acc,\n","                    \"precision\": precision,\n","                    \"recall\": recall,\n","                    \"f1_score\": f1,\n","                    \"confusion_matrix\": confusion_matrix(y_test_np, q_preds_np),\n","                    \"training_time\": quantum_training_time\n","                }\n","\n","        return quantum_results\n","\n","    except ImportError as e:\n","        print(f\"Qadence or other quantum packages not found: {e}\")\n","        print(\"Skipping quantum model.\")\n","        return None, None\n","    except Exception as e:\n","        print(f\"Error in quantum model: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None, None\n","\n","# =============================================================================\n","# Section 5: Quantum Evolution Kernel (QEK) Based Model\n","# =============================================================================\n","def train_and_evaluate_qek_model(X_train_scaled, X_test_scaled, y_train, y_test, feature_names=None):\n","    \"\"\"\n","    Train and evaluate a model using the Quantum Evolution Kernel (QEK).\n","    Preconfigured with optimal parameters from grid search.\n","\n","    Args:\n","        X_train_scaled: Scaled training features\n","        X_test_scaled: Scaled test features\n","        y_train: Training target\n","        y_test: Test target\n","        feature_names: Optional list of feature names\n","\n","    Returns:\n","        dict: Results from QEK model\n","    \"\"\"\n","    print(\"\\n----- Optimized Quantum Evolution Kernel (QEK) Model -----\")\n","    print(\"Using pre-configured optimal parameters: mu=1.0, C=100.0, samples=1200, bit_depth=3\")\n","\n","    # Import required libraries\n","    import numpy as np\n","    import time\n","    import traceback\n","    from sklearn.metrics import (\n","        accuracy_score, confusion_matrix, classification_report,\n","        precision_score, recall_score, f1_score, balanced_accuracy_score\n","    )\n","\n","    try:\n","        # Try to import QEK\n","        from qek.kernel import QuantumEvolutionKernel as QEK\n","        print(\"QEK library successfully imported\")\n","\n","        # Create a class for QEK data points\n","        class GraphStructuredDataPoint:\n","            \"\"\"\n","            Custom class with state_dict attribute for QEK.\n","            \"\"\"\n","            def __init__(self, state_dict, target=None):\n","                self.state_dict = state_dict\n","                self.target = target\n","\n","        # Check for NaN values\n","        if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n","            print(\"Warning: NaN values detected. Replacing with zeros.\")\n","            X_train_scaled_clean = np.nan_to_num(X_train_scaled)\n","            X_test_scaled_clean = np.nan_to_num(X_test_scaled)\n","        else:\n","            X_train_scaled_clean = X_train_scaled\n","            X_test_scaled_clean = X_test_scaled\n","\n","        # Feature to state dictionary conversion with optimal bit depth\n","        def feature_to_state_dict(features):\n","            \"\"\"\n","            Convert feature vector to a quantum state dictionary.\n","            Using bit_depth=3 based on grid search results.\n","            \"\"\"\n","            bit_depth = 3  # Optimal value from grid search\n","\n","            # Ensure features are positive (for probability distribution)\n","            if np.any(features < 0):\n","                # Shift distribution to be positive\n","                features = features - np.min(features)\n","\n","            # Get feature magnitudes\n","            features_abs = np.abs(features)\n","            sum_features = np.sum(features_abs)\n","\n","            # Normalize to valid probability distribution\n","            if sum_features < 1e-10:\n","                # Handle zero vectors\n","                probs = np.ones_like(features_abs) / len(features_abs)\n","            else:\n","                probs = features_abs / sum_features\n","\n","            # Create state dictionary\n","            state_dict = {}\n","\n","            # Get indices and sort by probability (highest first)\n","            idx_prob_pairs = [(i, p) for i, p in enumerate(probs)]\n","            idx_prob_pairs.sort(key=lambda x: x[1], reverse=True)\n","\n","            # Take top K probabilities or all if fewer\n","            K = min(2**bit_depth - 1, len(features))\n","            total_prob = 0.0\n","\n","            # Create binary representation for top K probabilities\n","            for i, (idx, prob) in enumerate(idx_prob_pairs[:K]):\n","                if prob > 1e-10:  # Only keep non-negligible probabilities\n","                    # Generate binary string of appropriate length\n","                    binary = format(i, f'0{bit_depth}b')\n","                    state_dict[binary] = float(prob)\n","                    total_prob += prob\n","\n","            # Ensure dictionary isn't empty\n","            if not state_dict:\n","                state_dict['0' * bit_depth] = 1.0\n","            elif total_prob < 0.99:\n","                # Normalize to ensure probabilities sum to 1\n","                for key in state_dict:\n","                    state_dict[key] /= total_prob\n","\n","            return state_dict\n","\n","        # Create dataset of appropriate size (1200 samples based on grid search)\n","        from sklearn.model_selection import StratifiedShuffleSplit\n","\n","        max_samples = 1200  # Optimal value from grid search\n","\n","        if len(X_train_scaled_clean) > max_samples:\n","            print(f\"Creating dataset with {max_samples} samples (optimal size from grid search)\")\n","            sss = StratifiedShuffleSplit(n_splits=1, test_size=1-max_samples/len(X_train_scaled_clean), random_state=42)\n","            for train_idx, _ in sss.split(X_train_scaled_clean, y_train):\n","                X_train_reduced = X_train_scaled_clean[train_idx]\n","                y_train_reduced = np.array(y_train)[train_idx]\n","        else:\n","            X_train_reduced = X_train_scaled_clean\n","            y_train_reduced = np.array(y_train)\n","\n","        # Similarly, limit test set size for efficient computation\n","        max_test_samples = min(200, len(X_test_scaled_clean))\n","        if len(X_test_scaled_clean) > max_test_samples:\n","            print(f\"Using {max_test_samples} test samples for efficient computation\")\n","            sss = StratifiedShuffleSplit(n_splits=1, test_size=1-max_test_samples/len(X_test_scaled_clean), random_state=42)\n","            for test_idx, _ in sss.split(X_test_scaled_clean, y_test):\n","                X_test_reduced = X_test_scaled_clean[test_idx]\n","                y_test_reduced = np.array(y_test)[test_idx]\n","        else:\n","            X_test_reduced = X_test_scaled_clean\n","            y_test_reduced = np.array(y_test)\n","\n","        print(f\"Using {len(X_train_reduced)} training samples and {len(X_test_reduced)} test samples\")\n","\n","        # Convert data to QEK format with state dictionaries\n","        train_data = [\n","            GraphStructuredDataPoint(feature_to_state_dict(x), y)\n","            for x, y in zip(X_train_reduced, y_train_reduced)\n","        ]\n","\n","        test_data = [\n","            GraphStructuredDataPoint(feature_to_state_dict(x), y)\n","            for x, y in zip(X_test_reduced, y_test_reduced)\n","        ]\n","\n","        # Print sample state dictionary\n","        print(f\"Sample state_dict format: {train_data[0].state_dict}\")\n","\n","        # Initialize QEK with optimal mu=1.0 from grid search\n","        print(\"Initializing QEK with optimal μ=1.0\")\n","        start_time = time.time()\n","        kernel = QEK(mu=1.0)  # Optimal value from grid search\n","\n","        # Compute kernel matrices in batches\n","        print(\"Computing kernel matrices...\")\n","        batch_size = 50  # Use batches for memory efficiency\n","\n","        n_train = len(train_data)\n","        n_test = len(test_data)\n","\n","        # Initialize kernel matrices\n","        K_train = np.zeros((n_train, n_train))\n","        K_test = np.zeros((n_test, n_train))\n","\n","        # Compute training kernel matrix in batches with progress reporting\n","        print(\"Generating training kernel matrix...\")\n","        for i in range(0, n_train, batch_size):\n","            print(f\"  Processing batch {i//batch_size + 1}/{(n_train-1)//batch_size + 1}\")\n","            batch_end = min(i + batch_size, n_train)\n","\n","            for j in range(0, n_train, batch_size):\n","                j_end = min(j + batch_size, n_train)\n","\n","                # Compute kernel values for this batch\n","                for bi in range(i, batch_end):\n","                    for bj in range(j, j_end):\n","                        try:\n","                            K_train[bi, bj] = kernel(train_data[bi], train_data[bj])\n","                            # Ensure symmetry for faster computation\n","                            if bi != bj:\n","                                K_train[bj, bi] = K_train[bi, bj]\n","                        except Exception as ke:\n","                            # Fallback for any kernel computation errors\n","                            print(f\"  Kernel computation error at ({bi},{bj}): {ke}\")\n","                            # Default to identity kernel in case of error\n","                            K_train[bi, bj] = 1.0 if bi == bj else 0.0\n","                            if bi != bj:\n","                                K_train[bj, bi] = K_train[bi, bj]\n","\n","        # Compute test kernel matrix in batches\n","        print(\"Generating test kernel matrix...\")\n","        for i in range(0, n_test, batch_size):\n","            print(f\"  Processing test batch {i//batch_size + 1}/{(n_test-1)//batch_size + 1}\")\n","            batch_end = min(i + batch_size, n_test)\n","\n","            for j in range(0, n_train, batch_size):\n","                j_end = min(j + batch_size, n_train)\n","\n","                # Compute kernel values for this batch\n","                for bi in range(i, batch_end):\n","                    for bj in range(j, j_end):\n","                        try:\n","                            K_test[bi, bj] = kernel(test_data[bi], train_data[bj])\n","                        except Exception as ke:\n","                            # Fallback for any kernel computation errors\n","                            print(f\"  Kernel computation error at test point ({bi},{bj}): {ke}\")\n","                            # Default to zero for test points in case of error\n","                            K_test[bi, bj] = 0.0\n","\n","        # Check for NaN or infinity values in kernel matrices\n","        if np.isnan(K_train).any() or np.isinf(K_train).any():\n","            print(\"Warning: NaN or Inf values in training kernel matrix. Replacing with zeros.\")\n","            K_train = np.nan_to_num(K_train)\n","\n","        if np.isnan(K_test).any() or np.isinf(K_test).any():\n","            print(\"Warning: NaN or Inf values in test kernel matrix. Replacing with zeros.\")\n","            K_test = np.nan_to_num(K_test)\n","\n","        # Train SVM with precomputed kernel using optimal C=100.0 from grid search\n","        print(\"Training SVM with precomputed kernel matrix (C=100.0)...\")\n","        from sklearn.svm import SVC\n","\n","        model = SVC(\n","            kernel='precomputed',\n","            random_state=42,\n","            class_weight='balanced',\n","            C=100.0  # Optimal value from grid search\n","        )\n","\n","        # Train with precomputed kernel matrix\n","        try:\n","            model.fit(K_train, y_train_reduced)\n","\n","            # Predict using precomputed kernel matrix\n","            y_pred_qek = model.predict(K_test)\n","            qek_training_time = time.time() - start_time\n","\n","            # Calculate evaluation metrics\n","            accuracy = accuracy_score(y_test_reduced, y_pred_qek)\n","            balanced_acc = balanced_accuracy_score(y_test_reduced, y_pred_qek)\n","            f1 = f1_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","            precision = precision_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","            recall = recall_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","\n","            # Print metrics\n","            print(\"\\nQEK-SVM Model Results:\")\n","            print(f\"  Accuracy: {accuracy:.4f}\")\n","            print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n","            print(f\"  Precision: {precision:.4f}\")\n","            print(f\"  Recall: {recall:.4f}\")\n","            print(f\"  F1 Score: {f1:.4f}\")\n","            print(f\"  Training Time: {qek_training_time:.4f} seconds\")\n","            print(f\"  Confusion Matrix:\\n{confusion_matrix(y_test_reduced, y_pred_qek)}\")\n","            print(f\"  Classification Report:\\n{classification_report(y_test_reduced, y_pred_qek, zero_division=0)}\")\n","\n","            # Store results\n","            qek_results = {\n","                \"accuracy\": accuracy,\n","                \"balanced_accuracy\": balanced_acc,\n","                \"precision\": precision,\n","                \"recall\": recall,\n","                \"f1_score\": f1,\n","                \"confusion_matrix\": confusion_matrix(y_test_reduced, y_pred_qek),\n","                \"training_time\": qek_training_time,\n","                \"parameters\": {\"mu\": 1.0, \"C\": 100.0, \"samples\": max_samples, \"bit_depth\": 3}\n","            }\n","\n","            return qek_results\n","\n","        except Exception as fit_error:\n","            print(f\"Error fitting SVM with QEK kernel: {fit_error}\")\n","            traceback.print_exc()\n","\n","            # If kernel matrix is invalid, attempt regularization\n","            print(\"Attempting to regularize kernel matrix...\")\n","            # Add small diagonal term to ensure positive definiteness\n","            np.fill_diagonal(K_train, np.diag(K_train) + 1e-10)\n","\n","            try:\n","                model.fit(K_train, y_train_reduced)\n","                y_pred_qek = model.predict(K_test)\n","                qek_training_time = time.time() - start_time\n","\n","                # Calculate evaluation metrics\n","                accuracy = accuracy_score(y_test_reduced, y_pred_qek)\n","                balanced_acc = balanced_accuracy_score(y_test_reduced, y_pred_qek)\n","                f1 = f1_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","                precision = precision_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","                recall = recall_score(y_test_reduced, y_pred_qek, average='weighted', zero_division=0)\n","\n","                # Print metrics\n","                print(\"\\nQEK-SVM Model Results (after regularization):\")\n","                print(f\"  Accuracy: {accuracy:.4f}\")\n","                print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n","                print(f\"  Precision: {precision:.4f}\")\n","                print(f\"  Recall: {recall:.4f}\")\n","                print(f\"  F1 Score: {f1:.4f}\")\n","                print(f\"  Training Time: {qek_training_time:.4f} seconds\")\n","\n","                # Store results\n","                qek_results = {\n","                    \"accuracy\": accuracy,\n","                    \"balanced_accuracy\": balanced_acc,\n","                    \"precision\": precision,\n","                    \"recall\": recall,\n","                    \"f1_score\": f1,\n","                    \"confusion_matrix\": confusion_matrix(y_test_reduced, y_pred_qek),\n","                    \"training_time\": qek_training_time,\n","                    \"parameters\": {\"mu\": 1.0, \"C\": 100.0, \"samples\": max_samples, \"bit_depth\": 3}\n","                }\n","\n","                return qek_results\n","\n","            except Exception as reg_error:\n","                print(f\"Regularization attempt failed: {reg_error}\")\n","                return None\n","\n","    except Exception as e:\n","        print(f\"Error in QEK model: {e}\")\n","        traceback.print_exc()\n","        return None\n","\n","\n","# =============================================================================\n","# Section 6: Comparison and Visualization\n","# =============================================================================\n","def visualize_results(classical_results,quantum_results , qek_results, df):\n","    \"\"\"\n","    Visualize and compare model results.\n","\n","    Args:\n","        classical_results: Results from classical models\n","        quantum_accuracy: Accuracy of quantum model\n","        quantum_training_time: Training time of quantum model\n","        qek_results: Results from QEK model\n","        df: Preprocessed dataframe\n","    \"\"\"\n","    if not classical_results and quantum_results is None and qek_results is None:\n","        print(\"No results to visualize.\")\n","        return\n","\n","    model_names = []\n","    accuracies = []\n","    balanced_accs = []\n","    precisions = []\n","    recalls = []\n","    f1_scores = []\n","    training_times = []\n","\n","    # Collect results from classical models\n","    if classical_results:\n","        for name, result in classical_results.items():\n","            model_names.append(name)\n","            accuracies.append(result[\"accuracy\"])\n","            balanced_accs.append(result[\"balanced_accuracy\"])\n","            precisions.append(result[\"precision\"])\n","            recalls.append(result[\"recall\"])\n","            f1_scores.append(result[\"f1_score\"])\n","            training_times.append(result[\"training_time\"])\n","\n","    # Add Qadence QNN results if available\n","    if quantum_results is not None:\n","        model_names.append(\"Quantum QNN\")\n","        accuracies.append(quantum_results[\"accuracy\"])\n","        balanced_accs.append(quantum_results[\"balanced_accuracy\"])\n","        precisions.append(quantum_results[\"precision\"])\n","        recalls.append(quantum_results[\"recall\"])\n","        f1_scores.append(quantum_results[\"f1_score\"])\n","        training_times.append(quantum_results[\"training_time\"])\n","\n","    # Add QEK results if available\n","    if qek_results is not None:\n","        model_names.append(\"QEK-SVM\")\n","        accuracies.append(qek_results[\"accuracy\"])\n","        balanced_accs.append(qek_results[\"balanced_accuracy\"])\n","        precisions.append(qek_results[\"precision\"])\n","        recalls.append(qek_results[\"recall\"])\n","        f1_scores.append(qek_results[\"f1_score\"])\n","        training_times.append(qek_results[\"training_time\"])\n","\n","    # 1. Plot model accuracies\n","    plt.figure(figsize=(12, 6))\n","    bars = plt.bar(model_names, accuracies, color='skyblue')\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(\"Model Accuracy Comparison\")\n","    plt.ylim(0, 1)\n","    plt.xticks(rotation=45)\n","\n","    # Add accuracy values on top of bars\n","    for bar, acc in zip(bars, accuracies):\n","        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n","                 f'{acc:.4f}', ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.savefig(\"model_accuracy_comparison.png\")\n","    plt.show()\n","\n","    # 2. Plot balanced accuracies (better for imbalanced data)\n","    plt.figure(figsize=(12, 6))\n","    bars = plt.bar(model_names, balanced_accs, color='lightgreen')\n","    plt.ylabel(\"Balanced Accuracy\")\n","    plt.title(\"Model Balanced Accuracy Comparison\")\n","    plt.ylim(0, 1)\n","    plt.xticks(rotation=45)\n","\n","    # Add balanced accuracy values on top of bars\n","    for bar, bacc in zip(bars, balanced_accs):\n","        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n","                 f'{bacc:.4f}', ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.savefig(\"model_balanced_accuracy_comparison.png\")\n","    plt.show()\n","\n","    # 3. Plot F1 scores\n","    plt.figure(figsize=(12, 6))\n","    bars = plt.bar(model_names, f1_scores, color='coral')\n","    plt.ylabel(\"F1 Score\")\n","    plt.title(\"Model F1 Score Comparison\")\n","    plt.ylim(0, 1)\n","    plt.xticks(rotation=45)\n","\n","    # Add F1 score values on top of bars\n","    for bar, f1 in zip(bars, f1_scores):\n","        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n","                 f'{f1:.4f}', ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.savefig(\"model_f1_score_comparison.png\")\n","    plt.show()\n","\n","    # 4. Plot training times\n","    plt.figure(figsize=(12, 6))\n","    bars = plt.bar(model_names, training_times, color='lightpink')\n","    plt.ylabel(\"Training Time (seconds)\")\n","    plt.title(\"Model Training Time Comparison\")\n","    plt.xticks(rotation=45)\n","\n","    # Add time values on top of bars\n","    for bar, time_val in zip(bars, training_times):\n","        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n","                 f'{time_val:.2f}s', ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.savefig(\"model_training_time_comparison.png\")\n","    plt.show()\n","\n","    # 5. Combined metrics chart\n","    plt.figure(figsize=(15, 8))\n","    x = np.arange(len(model_names))\n","    width = 0.2\n","\n","    plt.bar(x - width*1.5, accuracies, width, label='Accuracy', color='skyblue')\n","    plt.bar(x - width/2, balanced_accs, width, label='Balanced Accuracy', color='lightgreen')\n","    plt.bar(x + width/2, precisions, width, label='Precision', color='coral')\n","    plt.bar(x + width*1.5, recalls, width, label='Recall', color='lightpink')\n","\n","    plt.xlabel('Models')\n","    plt.ylabel('Scores')\n","    plt.title('All Metrics Comparison')\n","    plt.xticks(x, model_names, rotation=45)\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.savefig(\"all_metrics_comparison.png\")\n","    plt.show()\n","\n","    # 6. Display a correlation heatmap\n","    try:\n","        plt.figure(figsize=(12, 10))\n","        corr_matrix = df.corr()\n","        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask for upper triangle\n","\n","        sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\",\n","                    linewidths=0.5, mask=mask)\n","        plt.title(\"Feature Correlation Heatmap\")\n","        plt.tight_layout()\n","        plt.savefig(\"feature_correlation_heatmap.png\")\n","        plt.show()\n","    except Exception as e:\n","        print(f\"Error creating correlation heatmap: {e}\")\n","\n","# =============================================================================\n","# Main Function\n","# =============================================================================\n","def main():\n","    \"\"\"\n","    Main function to run the coral reef bleaching prediction pipeline.\n","    \"\"\"\n","    try:\n","        # 1. Load and preprocess data\n","        X_train_scaled, X_test_scaled, y_train, y_test, feature_names, df = load_and_preprocess_data()\n","\n","        # 2. Train and evaluate classical models\n","        classical_results = train_and_evaluate_classical_models(X_train_scaled, X_test_scaled, y_train, y_test)\n","\n","        # 3. Train and evaluate quantum model (QNN)\n","        quantum_results = train_and_evaluate_quantum_model(X_train_scaled, X_test_scaled, y_train, y_test)\n","\n","        # 4. Train and evaluate QEK model\n","        qek_results = train_and_evaluate_qek_model(X_train_scaled, X_test_scaled, y_train, y_test, feature_names)\n","\n","        # 5. Visualize results\n","        visualize_results(classical_results, quantum_results, qek_results, df)\n","\n","        # 6. Print final summary\n","        print(\"\\n----- Final Summary -----\")\n","        print(\"Top performing models:\")\n","        all_accuracies = []\n","\n","        for name, result in classical_results.items():\n","            all_accuracies.append((name, result[\"accuracy\"]))\n","\n","        if quantum_results is not None:\n","            all_accuracies.append((\"Quantum QNN\", quantum_results[\"accuracy\"]))\n","\n","        if qek_results is not None:\n","            all_accuracies.append((\"QEK-SVM\", qek_results[\"accuracy\"]))\n","\n","        # Sort by accuracy (descending)\n","        all_accuracies.sort(key=lambda x: x[1], reverse=True)\n","\n","        for i, (name, acc) in enumerate(all_accuracies):\n","            print(f\"{i+1}. {name}: {acc:.4f}\")\n","\n","        print(\"\\nFigures saved:\")\n","        print(\"- model_accuracy_comparison.png\")\n","        print(\"- model_balanced_accuracy_comparison.png\")\n","        print(\"- model_f1_score_comparison.png\")\n","        print(\"- model_training_time_comparison.png\")\n","        print(\"- all_metrics_comparison.png\")\n","        print(\"- feature_correlation_heatmap.png\")\n","\n","    except Exception as e:\n","        print(f\"Error in main function: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSuA_ind_xdD","executionInfo":{"status":"ok","timestamp":1741547925452,"user_tz":-60,"elapsed":11545,"user":{"displayName":"Vincenzo Schiano","userId":"04691900049132186889"}},"outputId":"573cf1f3-14d6-4fea-c22e-bdfd811efd18"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Coral Reef Bleaching Prediction using Classical and Quantum ML Approaches\n","Loading data from online URL: https://raw.githubusercontent.com/alyshapm/coral-reef-bleaching/main/dataset/NOAA_Reef_Check__Bleaching_Data.csv\n","Original dataset shape: (9111, 12)\n","  Bleaching     Ocean  Year  Depth Storms HumanImpact     Siltation Dynamite  \\\n","0        No  Atlantic  2005    4.0    yes        high         often     none   \n","1        No   Red Sea  2004    6.0     no        high  occasionally     none   \n","2        No   Pacific  1998    3.0     no         low         never     none   \n","3        No   Pacific  1998   10.0     no         low         never     none   \n","4        No  Atlantic  1997   10.0     no        high         never     none   \n","\n","  Poison Sewage Industrial Commercial  \n","0   none   high       none       none  \n","1   none    low       none       none  \n","2   none   none        low       none  \n","3   none   none        low       none  \n","4   none   high   moderate       none  \n","\n","Class distribution before cleaning:\n","Bleaching\n","No     6480\n","Yes     219\n","Name: count, dtype: int64\n","Positive rate: 3.27%\n","Shape after handling missing values: (6699, 12)\n","\n","Column data types:\n","Bleaching       object\n","Ocean           object\n","Year             int64\n","Depth          float64\n","Storms          object\n","HumanImpact     object\n","Siltation       object\n","Dynamite        object\n","Poison          object\n","Sewage          object\n","Industrial      object\n","Commercial      object\n","dtype: object\n","\n","Encoding categorical columns...\n","Encoded Bleaching to 1/0\n","Encoded Storms to 1/0\n","Encoded Ocean column\n","Unique values in Commercial before mapping: ['none' 'high' 'low' 'moderate']\n","Encoded Commercial column\n","Unique values in HumanImpact before mapping: ['high' 'low' 'none' 'moderate']\n","Encoded HumanImpact column\n","Unique values in Siltation before mapping: ['often' 'occasionally' 'never' 'always']\n","Warning: Column Siltation has 6699 NaN values after mapping\n","Unique values in Siltation after mapping: [nan]\n","Filled NaN values in Siltation with 0\n","Encoded Siltation column\n","Unique values in Dynamite before mapping: ['none' 'low' 'moderate' 'high']\n","Encoded Dynamite column\n","Unique values in Poison before mapping: ['none' 'low' 'moderate' 'high']\n","Encoded Poison column\n","Unique values in Sewage before mapping: ['high' 'low' 'none' 'moderate']\n","Encoded Sewage column\n","Unique values in Industrial before mapping: ['none' 'low' 'moderate' 'high']\n","Encoded Industrial column\n","\n","Warning: Dataset still contains NaN values:\n","Ocean    15\n","dtype: int64\n","Filling remaining NaN values...\n","\n","Correlations with Bleaching:\n","Correlation of Ocean with Bleaching: 0.0090\n","Correlation of Year with Bleaching: 0.2670\n","Correlation of Depth with Bleaching: 0.0060\n","Correlation of Storms with Bleaching: 0.0224\n","Correlation of HumanImpact with Bleaching: 0.0033\n","Correlation of Siltation with Bleaching: nan\n","Correlation of Dynamite with Bleaching: 0.0336\n","Correlation of Poison with Bleaching: 0.0220\n","Correlation of Sewage with Bleaching: 0.0017\n","Correlation of Industrial with Bleaching: 0.0141\n","Correlation of Commercial with Bleaching: 0.1454\n","Dropping low correlation features: ['Ocean', 'Depth', 'Storms', 'HumanImpact', 'Dynamite', 'Poison', 'Sewage', 'Industrial']\n","\n","Class distribution after preprocessing:\n","Bleaching\n","0    6480\n","1     219\n","Name: count, dtype: int64\n","Positive rate: 3.27%\n","Dataset is imbalanced. Using stratified sampling...\n","Training data shape: (5024, 3)\n","Test data shape: (1675, 3)\n","Training set positive rate: 3.26%\n","Test set positive rate: 3.28%\n","Minority class ratio: 3.26%\n","Using class weight 'balanced' for models due to imbalanced data\n","\n","----- Classical Model Results -----\n","Logistic Regression Results:\n","  Accuracy: 0.8621\n","  Balanced Accuracy: 0.9199\n","  Precision: 0.1901\n","  Recall: 0.9818\n","  F1 Score: 0.3186\n","  Training Time: 0.0149 seconds\n","  Confusion Matrix:\n","[[1390  230]\n"," [   1   54]]\n","  Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.86      0.92      1620\n","           1       0.19      0.98      0.32        55\n","\n","    accuracy                           0.86      1675\n","   macro avg       0.59      0.92      0.62      1675\n","weighted avg       0.97      0.86      0.90      1675\n","\n","-----\n","Decision Tree Results:\n","  Accuracy: 0.9176\n","  Balanced Accuracy: 0.9486\n","  Precision: 0.2827\n","  Recall: 0.9818\n","  F1 Score: 0.4390\n","  Training Time: 0.0039 seconds\n","  Confusion Matrix:\n","[[1483  137]\n"," [   1   54]]\n","  Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.92      0.96      1620\n","           1       0.28      0.98      0.44        55\n","\n","    accuracy                           0.92      1675\n","   macro avg       0.64      0.95      0.70      1675\n","weighted avg       0.98      0.92      0.94      1675\n","\n","-----\n","SVM Results:\n","  Accuracy: 0.8621\n","  Balanced Accuracy: 0.9199\n","  Precision: 0.1901\n","  Recall: 0.9818\n","  F1 Score: 0.3186\n","  Training Time: 1.0964 seconds\n","  Confusion Matrix:\n","[[1390  230]\n"," [   1   54]]\n","  Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.86      0.92      1620\n","           1       0.19      0.98      0.32        55\n","\n","    accuracy                           0.86      1675\n","   macro avg       0.59      0.92      0.62      1675\n","weighted avg       0.97      0.86      0.90      1675\n","\n","-----\n","Naive Bayes Results:\n","  Accuracy: 0.9176\n","  Balanced Accuracy: 0.9486\n","  Precision: 0.2827\n","  Recall: 0.9818\n","  F1 Score: 0.4390\n","  Training Time: 0.0015 seconds\n","  Confusion Matrix:\n","[[1483  137]\n"," [   1   54]]\n","  Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.92      0.96      1620\n","           1       0.28      0.98      0.44        55\n","\n","    accuracy                           0.92      1675\n","   macro avg       0.64      0.95      0.70      1675\n","weighted avg       0.98      0.92      0.94      1675\n","\n","-----\n","\n","----- Quantum Model (QNN) -----\n","Qadence or other quantum packages not found: No module named 'qadence'\n","Skipping quantum model.\n","\n","----- Optimized Quantum Evolution Kernel (QEK) Model -----\n","Using pre-configured optimal parameters: mu=1.0, C=100.0, samples=1200, bit_depth=3\n","Error in QEK model: No module named 'qek'\n","Error in main function: tuple indices must be integers or slices, not str\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"<ipython-input-1-af12138c6f5c>\", line 698, in train_and_evaluate_qek_model\n","    from qek.kernel import QuantumEvolutionKernel as QEK\n","ModuleNotFoundError: No module named 'qek'\n","Traceback (most recent call last):\n","  File \"<ipython-input-1-af12138c6f5c>\", line 1169, in main\n","    visualize_results(classical_results, quantum_results, qek_results, df)\n","  File \"<ipython-input-1-af12138c6f5c>\", line 1030, in visualize_results\n","    accuracies.append(quantum_results[\"accuracy\"])\n","                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","TypeError: tuple indices must be integers or slices, not str\n"]}]}]}